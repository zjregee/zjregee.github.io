[{"content":"加速日志回溯是Raft论文实现中的一个可选功能。如果在完成6.824的过程中不实现的话，会在Lab2B、Lab2C的测试中出现问题。原因在于，当leader的appendEntries被拒时，论文默认的解决方案时反复减一回退重试，导致耗费很长时间才能找到同步位置，优化后可以一次性跳过更多的index，减少RPC往复。加速日志回溯的优化对于使陈旧的follower快速更新是有用的。\n这一优化的实现方式并不是固定的，一个可能的原因在于作者认为在大多数部署中没有必要。在MIT的Student\u0026rsquo;s Guide to Raft中提出的实现方式如下：\n如果follower的日志中没有prevLogIndex，他应该以conflictIndex = len(log)和conflictTerm = None返回。 如果follower的日志中有prevLogIndex，但是term不匹配，他应该返回conflictTerm = log[prevLogIndex].Term，然后conflictIndex的值等于在他的日志中第一个term等于conflictTerm的日志索引。 在收到有冲突的回复后，leader应该首先在其日志中搜索conflictTerm。如果他在他的日志中发现有该term的日志条目，就将nextIndex设置为其日志中这个term的最后一个日志条目索引之后的那一个位置。 如果他没有找到term等于conflictTerm的日志条目，就设置nextIndex = conflictIndex。 还有一个折半的解决方案是只使用conflictIndex，从而简化实现。但这样一来，leader有时会向follower发送更多的日志条目，而不是严格意义上世纪需要的，从而使他们达到最新状态。\n","date":"2022-01-02T00:00:00Z","permalink":"https://zjregee.github.io/p/raft%E4%B8%AD%E7%9A%84%E5%8A%A0%E9%80%9F%E6%97%A5%E5%BF%97%E5%9B%9E%E6%BA%AF/","title":"Raft中的加速日志回溯"},{"content":"今天来学习一下xv6关于锁相关的实现。相信学习如何在内核中使用锁也能帮助我们在日常使用中更好地理解锁的机制。\n感兴趣的朋友可以直接看xv6 book Chapter 6以及源码的实现。\nhttps://pdos.csail.mit.edu/6.S081/2020/xv6/book-riscv-rev1.pdf\nhttps://github.com/mit-pdos/xv6-riscv\nAbstract 大多数内核，包括xv6，都是交错执行多个活动的。交错执行的一个来源是多处理器硬件：有多个CPU独立执行的计算机，如xv6的RISC-V。这些多个CPU共享物理RAM，xv6利用这种共享来维护所有CPU都能读和写的数据结构。\n这种共享造成了当CPU并行访问数据结构并更新他时如果不仔细设计这个过程可能会产生不正确的结果或损坏的数据结构。即使在单个处理器上，内核也可能在多个线程之间切换CPU运行的线程，导致他们的执行是交错进行的。以及，如果一个设备中断处理程序修改了一些可中断代码相同的数据，而中断恰好发生在了暧昧的时间点，就会损坏数据。\nConcurrency一词是指由于多处理器的并行性、线程切换或中断，导致多个指令流交错的情况。\n内核中充满了并发访问的数据。例如，两个CPU可以同时调用kalloc，从而同时从free list的头部弹出。内核设计者喜欢允许大量的并发，因为它可以通过并行性产生更多的性能，并增加响应性。\n为了在并发场景下得到正确的代码，有些方法比其他方法更容易推理。旨在实现并发性下的正确性的策略，以及支持这些策略的抽象，就被称为并发控制技术。\nXv6使用了许多并发控制技术，这取决于情况；还有许多可能。我们接下来重点介绍一种广泛使用的技术：锁。锁提供了相互排斥的功能，确保每次只有一个CPU可以持有该锁。如果程序员将锁与每个共享数据项相关联，并且代码在使用某个项目时总是持有相关的锁，那么该项目在同一时间只能被一个CPU使用。在这种情况下，我们说锁是保护数据项的。尽管锁是一种易于理解的并发控制机制，但锁的缺点是它们会扼杀性能，因为它们会将并发操作序列化。\n值得一提的是，内核设计中的一个主要挑战是避免锁的争夺。Xv6在这方面做得很少，但是复杂的内核专门组织数据结构和算法来避免锁的争夺。The rest of this blog explains why xv6 needs locks, how xv6 implements them, and how it uses them.\nRace conditions 这里xv6 book举了一个两个进程并发调用kfree()的例子。在这里省略。\n一些bug小技巧。\n竞争的结果取决于所涉及的两个cpu的准确时间，以及它们的内存操作是如何由内存系统排序的，这可能会使竞争导致的错误难以重现和调试。例如，在调试推时添加print语句可能会改变执行的时间，从而使竞争消失。\n你可以把锁看作是对并发的关键部分的序列化，这样它们就可以一次运行一个，从而保留不变性（假设关键部分在隔离状态下是正确的）。你也可以认为由同一个锁保护的关键部分是相互原子的，因此每个关键部分只能看到来自早期关键部分的完整变化，而不会看到部分完成的更新。\nCode: Locks Xv6中有两种锁：spinlocks以及sleep-locks。我们先介绍第一个spinlocks。\n// Mutual exclusion lock. struct spinlock { uint locked; // Is the lock held? // For debugging: char *name; // Name of lock. struct cpu *cpu; // The cpu holding the lock. }; locked是其中的重要字段，当锁可用时为0，当锁被持有时为非0。\n一个错误的获取锁的版本：\nvoid acquire(struct spinlock *lk) { for(;;) { if(lk-\u0026gt;locked == 0) { lk-\u0026gt;locked = 1; break; } } } 这个实现并不能保证多处理器上的互斥。一个很可能发生的情况是，两个CPU同时判断lk的值为0，并都通过执行赋值语句获取锁。这样，两个不同的CPU都持有了锁，这显然违反了我们的需求。我们需要的是一种使得对于锁的判断和修改作为一个原子步骤执行的方法。\n由于锁被广泛使用，多核处理器通常提供指令来实现这一原子操作。在RISC-V上，这个指令是amoswap r, a。amoswap读取内存地址a的值，将寄存器r的内容写入该地址，并将读取的值放入r。它以原子方式执行这个序列，使用特殊的硬件来防止任何其他CPU在读和写之间使用内存地址。\n这让我想到了之前blog中的无锁数据结构实现，同样需要底层硬件的特殊支持。\nXv6中的实现：\n// Acquire the lock. // Loops (spins) until the lock is acquired. void acquire(struct spinlock *lk) { push_off(); // disable interrupts to avoid deadlock. if(holding(lk)) panic(\u0026#34;acquire\u0026#34;); // On RISC-V, sync_lock_test_and_set turns into an atomic swap: // a5 = 1 // s1 = \u0026amp;lk-\u0026gt;locked // amoswap.w.aq a5, a5, (s1) while(__sync_lock_test_and_set(\u0026amp;lk-\u0026gt;locked, 1) != 0) ; // Tell the C compiler and the processor to not move loads or stores // past this point, to ensure that the critical section\u0026#39;s memory // references happen strictly after the lock is acquired. // On RISC-V, this emits a fence instruction. __sync_synchronize(); // Record info about lock acquisition for holding() and debugging. lk-\u0026gt;cpu = mycpu(); } Xv6获取锁的函数使用了可移植的C官方库调用__sync_lock_test_and_set，他可以执行底层的amoswap指令。返回值是lk→locked的旧内容。\n如果 前面的值是0，那么我们已经获得了锁，交换将把lk-\u0026gt;locked设置为1。如果之前的值是1，那么其他CPU持有该锁，而且我们原子式地将1换到lk-\u0026gt;locked中并没有改变其值。这是一个循环自旋的过程。\nvoid release(struct spinlock *lk) { if(!holding(lk)) panic(\u0026#34;release\u0026#34;); lk-\u0026gt;cpu = 0; // Tell the C compiler and the CPU to not move loads or stores // past this point, to ensure that all the stores in the critical // section are visible to other CPUs before the lock is released, // and that loads in the critical section occur strictly before // the lock is released. // On RISC-V, this emits a fence instruction. __sync_synchronize(); // Release the lock, equivalent to lk-\u0026gt;locked = 0. // This code doesn\u0026#39;t use a C assignment, since the C standard // implies that an assignment might be implemented with // multiple store instructions. // On RISC-V, sync_lock_release turns into an atomic swap: // s1 = \u0026amp;lk-\u0026gt;locked // amoswap.w zero, zero, (s1) __sync_lock_release(\u0026amp;lk-\u0026gt;locked); pop_off(); } Xv6释放锁时同样采用了一个原子性的操作。这是因为C标准允许编译器用多条存储指令来实现一个赋值，所以一个C的赋值对于并发代码来说可能是非原子性的。使用__sync_lock_release，可以实现原子性的赋值。这个函数的底层也是执行了amoswap指令。\n// Check whether this cpu is holding the lock. // Interrupts must be off. int holding(struct spinlock *lk) { int r; r = (lk-\u0026gt;locked \u0026amp;\u0026amp; lk-\u0026gt;cpu == mycpu()); return r; } Code: Using locks A hard part about using locks is deciding how many locks to use and which data and invariants each lock should protect. There are a few basic principles.\nFirst, any time a variable can be written by one CPU at the same time that another CPU can read or write it, a lock should be used to keep the two operations from overlapping. Second, remember that locks protect invariants: if an invariant involves multiple memory locations, typically all of them need to be protected by a single lock to ensure the invariant is maintained. 有时使用更细粒度的锁可以提高性能。\n6.S081的Lab Lock就是需要通过改写更细粒度的锁来减少竞争锁的次数。\nDeadlock and lock ordering 如果一个通过内核的代码路径必须同时持有几个锁，那么所有的代码路径以相同的顺序获得这些锁是很重要的。如果他们不这样做，就会有死锁的风险。假设xv6中的两个代码路径需要锁A和B，但是代码路径1按照先A后B的顺序获取锁，而另一个路径按照先B后A的顺序获取锁。假设线程T1执行代码路径1并获取了锁A，线程T2执行代码路径2并获取了锁B。为了避免这种死锁，所有的代码路径必须以相同的顺序获取锁。对全局锁获取顺序的需求意味着锁实际上是每个函数规范的一部分：调用者必须以一种方式调用函数，使锁按照商定的顺序被获取。\n遵守一个全局性的避免死锁的顺序可能是令人惊讶的困难。有时，锁的顺序与逻辑程序结构相冲突，例如，也许代码模块M1调用模块M2，但锁的顺序要求M2的锁在M1的锁之前被获取。\n有时，锁的身份并不事先知道，也许是因为必须持有一个锁，才能发现下一个要获取的锁的身份。这种情况出现在文件系统中，因为它在路径名称中寻找连续的组件，也出现在等待和退出的代码中，因为它们搜索进程表寻找子进程。最后，死锁的危险往往限制了人们对锁定方案的细化程度，因为更多的锁往往意味着更多的死锁机会。避免死锁的需要往往是内核实现的一个主要因素。\nLocks and interrupt handlers 一些xv6 spinlocks保护线程和中断处理程序都使用的数据。\n比如，clockintr定时器中断处理程序可能在内核线程中读取sys_sleep中的ticks的同时增加ticks。锁tickslock将这两个访问序列化。spinlocks和中断的交互带来了潜在的危险.\n假设sys_sleep持有tickslock，而它的CPU被一个定时器中断所打断，clockintr会试图获取tickslock，看到它被持有，并等待它被释放。在这种情况下，tickslock将永远不会被释放：只有sys_sleep可以释放它，但是sys_sleep不会继续运行，直到clockintr返回。所以CPU会死锁，任何需要这两个锁的代码也会无法运行。\nvoid clockintr() { acquire(\u0026amp;tickslock); ticks++; wakeup(\u0026amp;ticks); release(\u0026amp;tickslock); } uint64 sys_sleep(void) { int n; uint ticks0; if(argint(0, \u0026amp;n) \u0026lt; 0) return -1; acquire(\u0026amp;tickslock); ticks0 = ticks; while(ticks - ticks0 \u0026lt; n){ if(myproc()-\u0026gt;killed){ release(\u0026amp;tickslock); return -1; } sleep(\u0026amp;ticks, \u0026amp;tickslock); } release(\u0026amp;tickslock); return 0; } 为了避免这种情况，如果一个spinlock被一个中断处理程序使用，CPU决不能在启用中断的情况下持有该锁。\nXv6采用了更为保守的策略：当一个CPU获得任何锁时，xv6总是禁用该CPU上的中断。中断仍然可能发生在其他CPU上，所以中断获取锁可以等待线程释放spinlock；只是不能在同一个CPU上。\n当CPU不持有spinlock时，xv6会重新启用中断。因此必须记录CPU持有锁的情况。acquire会调用push_off，release会调用pop_off，以跟踪当前CPU锁的嵌套级别（之前的实现包括了这一部分）。\n// push_off/pop_off are like intr_off()/intr_on() except that they are matched: // it takes two pop_off()s to undo two push_off()s. Also, if interrupts // are initially off, then push_off, pop_off leaves them off. void push_off(void) { int old = intr_get(); intr_off(); if(mycpu()-\u0026gt;noff == 0) mycpu()-\u0026gt;intena = old; mycpu()-\u0026gt;noff += 1; } void pop_off(void) { struct cpu *c = mycpu(); if(intr_get()) panic(\u0026#34;pop_off - interruptible\u0026#34;); if(c-\u0026gt;noff \u0026lt; 1) panic(\u0026#34;pop_off\u0026#34;); c-\u0026gt;noff -= 1; if(c-\u0026gt;noff == 0 \u0026amp;\u0026amp; c-\u0026gt;intena) intr_on(); } // Per-CPU state. struct cpu { struct proc *proc; // The process running on this cpu, or null. struct context context; // swtch() here to enter scheduler(). int noff; // Depth of push_off() nesting. int intena; // Were interrupts enabled before push_off()? }; 当noff计数达到0时，pop_off恢复最外层数据竞争区开始时中断启动的状态。\nintr_off和intr_on函数执行RISC-V指令，来禁用和启用中断。\n需要的注意是只有释放了锁才可以调用pop_off，避免短暂的窗口造成死锁。\nInstruction and memory ordering 很自然地会认为程序是按照源代码语句出现的顺序来执行的。然而，许多编译器和CPU会不按顺序执行代码，以达到更高的性能。如果一条指令需要很多周期才能完成，CPU可能会提前发出该指令，以便与其他指令重叠，避免CPU停顿。例如，CPU可能注意到在一个串行的指令序列中，A和B并不是相互依赖的。CPU可能会先启动指令B，因为它的输入在A的输入之前就已经准备好了，或者是为了与A和B的执行重叠。编译器可能会进行类似的重新排序，在源码中一个语句的指令之前发出该语句的指令。\n编译器和CPU在重新排序时遵循规则，以确保它们不会改变正确编写的串行代码的结果。然而，这些规则确实允许重新排序，改变并发代码的结果，并且很容易导致多处理器上的不正确行为。CPU的排序规则被称为内存模型。\n这样的重排序会造成短暂的窗口达成死锁可能的条件。为了告诉硬件和编译器不要进行这样的重新排序。Xv6在spinlocks的acquire和release函数中都是用了__sync_synchronize()。这是一个内存屏障：他告诉编译器和CPU不要在屏障上重新排序加载或存储。\nSleep locks 有时xv6需要长时间地保持一个锁。例如，文件系统在磁盘上读写文件内容时，会保持一个文件的锁，这些磁盘操作可能需要几十毫秒。长时间的持有这个锁会导致，如果另一个进程想获取这个文件，需要保持这么长的循环等待时间从而导致浪费CPU的浪费。另一个spinlocks的缺点是当CPU持有一个锁后，他无法主动的yield让出进程；我们需要实现这个这样当一个进程持有锁在等待磁盘数据时，另一个进程可以使用CPU。在这里持有spinlock的进程yield的行为是禁止的，因为如果之后的进程去获取这个锁就会导致死锁。第二个进程会陷入死循环且无法让第一个进程得到CPU从而去释放锁。另外，在持有锁的情况下让出CPU，也违反了在持有spinlocks时必须关闭中断的要求。在如上需求的背景下，我们希望有一种锁，在等待获取时让出CPU，在持有锁时允许让出和中断。\n// Long-term locks for processes struct sleeplock { uint locked; // Is the lock held? struct spinlock lk; // spinlock protecting this sleep lock // For debugging: char *name; // Name of lock. int pid; // Process holding lock }; void initsleeplock(struct sleeplock *lk, char *name) { initlock(\u0026amp;lk-\u0026gt;lk, \u0026#34;sleep lock\u0026#34;); lk-\u0026gt;name = name; lk-\u0026gt;locked = 0; lk-\u0026gt;pid = 0; } void acquiresleep(struct sleeplock *lk) { acquire(\u0026amp;lk-\u0026gt;lk); while (lk-\u0026gt;locked) { sleep(lk, \u0026amp;lk-\u0026gt;lk); } lk-\u0026gt;locked = 1; lk-\u0026gt;pid = myproc()-\u0026gt;pid; release(\u0026amp;lk-\u0026gt;lk); } void releasesleep(struct sleeplock *lk) { acquire(\u0026amp;lk-\u0026gt;lk); lk-\u0026gt;locked = 0; lk-\u0026gt;pid = 0; wakeuzip(lk); release(\u0026amp;lk-\u0026gt;lk); } int holdingsleep(struct sleeplock *lk) { int r; acquire(\u0026amp;lk-\u0026gt;lk); r = lk-\u0026gt;locked \u0026amp;\u0026amp; (lk-\u0026gt;pid == myproc()-\u0026gt;pid); release(\u0026amp;lk-\u0026gt;lk); return r; } Spin-locks最适合用于短的关键部分，因为等待他们会浪费CPU时间，sleep-locks对长时间的操作很有效。\n这里的sleep会在之后介绍Scheduling的blog里详细介绍。\nReal world 大多数操作系统支持POSIX线程（Pthreads），它允许一个用户进程在不同的CPU上有几个线程同时运行。Pthreads支持用户级锁、屏障等。支持Pthreads需要操作系统的支持。例如，如果一个pthread在系统调用中阻塞，同一进程的另一个pthread应该能够在该CPU上运行。再比如，如果一个pthread改变了其进程的地址空间（例如，映射或解映射内存），内核必须安排其他运行同一进程的线程的CPU更新其硬件页表以反映地址空间的变化。\n有可能在没有原子指令的情况下实现锁，但它很昂贵，而且大多数操作系统都使用原子指令。\n如果许多CPU试图在同一时间获得相同的锁，那么锁就会很昂贵。如果一个CPU在其本地缓存中有一个锁，而另一个CPU必须获得该锁，那么更新持有该锁的缓存行的原子指令必须将该行从一个CPU的缓存中移到另一个CPU的缓存中，并且可能使该缓存行的任何其他副本失效。从另一个CPU的高速缓存中获取一个高速缓存行可能比从本地高速缓存中获取一个高速缓存行要贵上几个数量级。\n关于多个CPU之间缓存的同步以及其他各种问题，可以参考《Is Parallel Programming Hard, And, If So, What Can You Do About It?》附录C Why Memory Barriers?。之前简单看了一点前面的部分，希望之后有时间可以再看看。\n为了避免与锁相关的开销，许多操作系统使用无锁数据结构和算法。然而，无锁编程比有锁编程更复杂；例如，人们必须担心指令和内存的重新排序问题。用锁编程已经很困难了，所以xv6避免了无锁编程的额外复杂性。\n关于无锁编程可以参考之前的一片blog https://zjregee.github.io/p/lock-free-programming/。\n","date":"2021-12-03T00:00:00Z","permalink":"https://zjregee.github.io/p/xv6%E7%B3%BB%E5%88%97%E5%AF%BC%E8%AF%BB%E4%B9%8Blocking/","title":"Xv6系列导读之Locking"},{"content":"今天做了6.S081的Lab Multithreading，需要实现一个最简单的协程。在很早以前，就知道了协程的概念，看了一些协程和线程的区别，一直觉得还是很模糊。直到今天才恍然大悟，不得不说，自己动手真的才是最好的学习方式。\n协程技术的本质上是一种程序控制机制。他和线程有非常多的相似之处，比如都有自己的堆栈，自己的局部变量。但是线程的切换是要陷入内核态，而协程是在用户态完成了寄存器和堆栈的切换。这就导致了某种意义上协程是可以更加高效的。\n线程可以并发运行，线程之间不能共享全局变量。\n协程不能并发运行，协程之间可以共享全局变量。\n因为协程不需要陷入内核，所以我们在使用各种语言实现自己的协程库时，需要自己实现一个汇编代码，完成寄存器的存储操作。\n这是XV6的线程切换实现。其中scheduler是一个内核中的常驻线程，一直处于一个死循环中，当这个线程被调用，就完成线程切换的操作。在线程切换中和协程切换一样。或者应该说协程切换和线程切换一样，需要保存context，即上下文。包括寄存器的值和堆栈情况。寄存器中的值就包含了程序运行的位置。下一次切换就可以继续这个位置运行。当切换线程时，需要把寄存器的值保存在内存数据结构中。\n下面是一个简单的实现线程切换的汇编代码示例。具体的汇编代码需要和程序运行的系统环境决定。\n.globl swtch swtch: sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret context，协程和线程运行的上下文。\nstruct context { uint64 ra; uint64 sp; // callee-saved uint64 s0; uint64 s1; uint64 s2; uint64 s3; uint64 s4; uint64 s5; uint64 s6; uint64 s7; uint64 s8; uint64 s9; uint64 s10; uint64 s11; }; 协程可以分为非对程式协程和对称式协程。他们提供传递程序控制权的操作有不同。yield就是一种主动放弃运行的操作。\n虽然这个实验本身难度不大，但确实让我增长了见识，对协程有更多的理解后，对Go协程的调度掌握的也更扎实了。\n一个C的协程实现，之后可以详细看看\nhttps://github.com/cloudwu/coroutine\n","date":"2021-12-02T00:00:00Z","permalink":"https://zjregee.github.io/p/%E4%BB%8E%E4%B8%80%E4%B8%AAlab%E7%90%86%E8%A7%A3%E5%8D%8F%E7%A8%8B/","title":"从一个Lab理解协程"},{"content":"从最基本的层面看，数据库只需要做两件事：向它插入数据时，它就保存数据；之后查询时，它应该返回那些数据。\n我们先来看两个Bash函数。\n#!/bin/bash db_set() { echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database } db_get() { grep \u0026#34;^$1,\u0026#34; database | sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1 } 这两个函数实现了一个key-value存储。当调用db_set key value，它将在数据库中保存你输入的key和value。然后，调用db_get key，它会查找与输入key相关联的最新值并返回。\n它底层的存储格式非常简单：一个纯文本文件。其中每行包含一个key-value对，用逗号分隔。每次调用db_set即追加新内容到文件末尾，因此，如果多次更新某个键，旧版本的值不会被覆盖，而是需要查看文件中最后一次出现的键来找到最新的值，\n显然，到这里我们已经实现了之前我们提到的两个需求，插入数据和查询数据。从这个角度看，世界上最简单的数据库就这样完成了。对于简单的情况，追加到文件尾部方式通常足够高效。另一方面，如果日志文件保存了大量的记录，那么db_get函数的性会非常差。每次想查找一个键，db_get必须从头到尾扫描整个数据库文件来查找键的出现位置。\n为了高效地查找数据库中特定键的值以及满足各种操作的需要，我们需要新的更为复杂的数据结构。实现一个数据库的方式有很多，索引结构也有很多类型，在这里我们以github的一个6k star的sqlite demo为例，介绍一个B-Tree的数据库实现。\n项目地址：https://github.com/cstack/db_tutorial\n配备文档：https://cstack.github.io/db_tutorial/\n可以直接看源码，不超过一千行的实现，源码非常好理解。\nB-tree B-tree被广泛用作索引结构。作为一种1970年推出的数据结构，时至今日，它仍然是几乎所有关系数据库中的标准索引实现，许多非关系型数据库也经常使用。B-tree将数据库分解为固定大小的块或页，传统上大小为4KB，页是内部读/写的最小单元。这种设计更接近底层硬件。\n篇幅受限，这里不过多介绍B-tree的基本知识，想要详细的了解可以Google更多资料。\n数据库设计 上图是sqlite的架构设计。一个数据库查询，会通过一系列组件来检索或修改数据。\n前端包括：\ntokenizer parser code generator 前端的输入是一个SQL查询，输出是sqlite虚拟机字节码。在我们的demo里前端的主要功能就是解析并检查SQL命令，调用对应的函数执行相应的操作。\n后端包括：\nvirtual machine：虚拟机把由前端生成的字节码作为指令。然后它可以对一个或多个表或索引进行操作，每个表或索引都存储在一个B树中。虚拟机本质上是一个关于字节码指令类型的switch语句。 B-tree：每个B树由许多节点组成。每个节点大小为1页，也就是4KB。B树可以通过向Pager发出命令从磁盘上检索一个页面或将其保存回磁盘。 pager：pager接受读取或写入数据页的命令。它负责读取/写入数据库文件中适当的偏移量。它还在内存中保存最近访问的页面的缓存，并确定何时需要将这些页面写回磁盘。 os interface：提供相应的系统调用。 我们给我们的数据库一些限制条件以简化编程：\n支持两种操作：插入一行和打印出所有行。 支持一个单一且硬编码的表。 上图是一个数据库中B树的存储结构的示例。叶子结点和中间节点有不同的布局。每个节点对应着1页。中间节点通过存储子节点的页号来指向子节点。B树传给pager特定的页号，pager从页缓存中返回指向对应页的指针。所有页都按照页号的顺序连续存储在数据库文件中。\n节点需要在页的头部存储一些元数据。每一个节点会存储节点种类，是否是根节点，以及父节点的页号（从而允许寻找兄弟节点的操作）。下面是每一个节点都需要的元数据大小和偏移的定义。\n/* * Common Node Header Layout */ const uint32_t NODE_TYPE_SIZE = sizeof(uint8_t); const uint32_t NODE_TYPE_OFFSET = 0; const uint32_t IS_ROOT_SIZE = sizeof(uint8_t); const uint32_t IS_ROOT_OFFSET = NODE_TYPE_SIZE; const uint32_t PARENT_POINTER_SIZE = sizeof(uint32_t); const uint32_t PARENT_POINTER_OFFSET = IS_ROOT_OFFSET + IS_ROOT_SIZE; const uint8_t COMMON_NODE_HEADER_SIZE = NODE_TYPE_SIZE + IS_ROOT_SIZE + PARENT_POINTER_SIZE; 除了这些常规的元数据，叶子节点还需要存储保存了多少key/value对。\n/* * Leaf Node Header Layout */ const uint32_t LEAF_NODE_NUM_CELLS_SIZE = sizeof(uint32_t); const uint32_t LEAF_NODE_NUM_CELLS_OFFSET = COMMON_NODE_HEADER_SIZE; const uint32_t LEAF_NODE_HEADER_SIZE = COMMON_NODE_HEADER_SIZE + LEAF_NODE_NUM_CELLS_SIZE; 在叶子节点中的元数据之后，就是保存的所有key/value对。每个key/value都按照一定的序列化规则保存。基于这些设定的参数，下面就是一个叶子节点对应页的布局。中间节点的具体布局也类似，但也有自己不一样的地方。\n插入数据 找到待插入key对应的页号以及页中的插入位置 找到B树的根节点 如果根节点是叶子节点，在叶子节点内进行二分查找插入位置 如果根节点是中间节点，找到待插入key对应的子节点，判断子节点的类型，如果子节点是叶子节点，则进行二分查找，否则继续递归查找子节点 插入key-value对，并根据插入情况进行B树的平衡，节点的分裂操作 相关资料 《DDIA》\nLSM-Tree\nhttps://cstack.github.io/db_tutorial/\n","date":"2021-10-28T00:00:00Z","permalink":"https://zjregee.github.io/p/%E7%AE%80%E6%98%93%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E7%8E%B0%E4%BB%8E0%E5%88%B01/","title":"简易数据库实现：从0到1"},{"content":"今天在看《Redis设计与实现》，没想到看的很快，感觉这本书还是非常通俗易懂的，对Redis的实际实现也讲的比较全面，对于像我一样的小白还是非常推荐的。在这里介绍一下Redis中的事务\nAbstract 为啥要取abstract，可能是因为最近看论文有点PTSD了\nRedis通过MULTI、EXEC、WATCH等命令来实现事务功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求\n事务的实现 一个事务从开始到结束通常会经历以下三个阶段：\n事务开始 命令入队 事务执行 事务开始 MULTI命令的执行标志着事务的开始\n将执行该命令的客户端从非事务状态切换至事务状态，这一切换是通过在客户端状态的flags属性中打开REDIS_MULTI标识来完成的\n这里的客户端指的是在Redis服务器中存着客户端状态的数据结构\n命令入队 当一个客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行\n但是，当一个客户端切换到事务状态之后，服务器会根据这个客户端发来的不同命令执行不同的操作\n如果客户端发送的命令为EXEC、DISCARD、WATCH、MULTI四个命令的其中一个，那么服务器立即执行这个命令 如果客户端发送的命令是EXEC、DISCARD、WATCH、MULTI四个命令以外的其他命令，那么服务器并不立即执行这个命令，而是将这个命令放入一个事务队列里面，然后向客户端返回QUEUED回复 事务队列 每个Redis客户端都有自己的事务状态，这个事务状态保存在客户端状态的mstate属性里面\n事务状态包含一个FIFO的事务队列，以及一个已入队命令的计数器，也就是事务队列的长度\n事务队列是一个multiCmd类型的数组，数组中的每个multiCmd结构都保存了一个已入队命令的相关信息，包括指向命令实现函数的指针、命令的参数，以及参数的数量\ntypedef struct redisClient { // ... multiState mstate; // ... } redisClient; typedef struct multiState { multiCmd *commands; int count; } multiState; typedef struct multiCmd { robj **argv; // 参数 int argc; // 参数数量 struct redisCommand *cmd; // 命令指针 } multiCmd; 执行事务 当一个处于事务状态的客户端向服务器发送EXEC命令时，这个EXEC命令将立即被服务器执行。服务器会变遍历这个客户端的事务队列，执行队列中保存的所有命令，最后将执行命令所得的结果全部返回给客户端\nWATCH命令的实现 WATCH命令是一个乐观锁，他可以在EXEC命令执行之前，监视任意数量的数据库键，并在EXEC命令执行时，检查被监视的键是否至少有一个已经被修改过了，如果是的话，服务器将拒绝执行事务，并向客户端返回代表事务执行失败的空回复\n接下来介绍下WATCH命令的实现原理，以及事务系统如何监视某个键，并在键被修改的情况下，确保事务的安全性\n使用WATCH命令监视数据库键 每个Redis数据库都保存着一个watched_keys字典，这个字典的键是某个被WATCH命令监视的数据库键，字典的值则是一个链表，链表中记录了所有监视相应数据库键的客户端\n通过这个字典，服务器可以清楚的知道哪些数据库键正在被监视，以及哪些客户端正在监视这些数据库键\n监视机制的触发 所有对数据库进行修改的命令，在执行后都会调用相应的函数对watched_keys字典进行检查，查看是否有客户端正在监视刚刚被命令修改过的数据库键，如果有的话，那么这个函数就会将监视被修改键的客户端的REDIS_DIRTY_CAS标识打开，表示该客户端的事务安全性已经被破坏\n判断事务是否安全 当服务器接收到一个客户端发来的EXEC命令时，服务器会根据这个客户端是否打开了REDIS_DIRTY_CAS标识来决定是否执行事务。如果这个标识没有被打开，就执行客户端提交的这个事务\n事务的ACID性质 传统的关系数据库中，常常用ACID性质来校验事务功能的可靠性和安全性\n在Redis中，事务总是具有原子性、一致性和隔离性，在Redis运行在某种特定的持久化模式中，事务也具有耐久性\n原子性 对于Redis的事务功能来说，事务队列中的命令要么就全部都执行，要么就一个都不执行，因此，Redis的事务是具有原子性的\n但是，Redis的事务和传统的关系型数据库事务的最大区别在于，Redis不支持事务回滚机制rollback，即使事务队列中的某个命令在执行期间出现了错误，整个事务也会继续执行下去，直到将事务队列中的所有命令都执行完毕为止\n这是因为Redis的作者认为这种复杂的功能和Redis追求简单高效的设计主旨不相符，并且认为事务的执行时遇到错误通常都是编程错误产生的，这种错误通常只会出现在开发环境，没有必要开发事务回滚功能\n一致性 一致性指数据符合数据库本身的定义和要求，没有包含非法或者无效的错误数据\nRedis通过谨慎的错误检测和简单的设计来保证事务的一致性\n隔离性 Redis在实际执行事务时是单线程的，并且，服务器保证在执行事务时不会对事务进行中断。Redis的事务总是以串行的方式运行的，总是具有隔离性的\n持久性 Redis事务的持久性由Redis使用的持久化模式决定\n但是，在一个事务的最后加上SAVE命令总可以保证事务的耐久性\n不过这种做法效率较低，不具有实用性\n","date":"2021-10-11T00:00:00Z","permalink":"https://zjregee.github.io/p/redis%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0/","title":"Redis中的事务实现"},{"content":"今天看到了一个非常有意思的算法，是目前针对统计二进制中1的个数这个问题的效率最好的通用算法，在这里记录一下。\n要解决的问题 编写一个函数，输入是一个无符号整数（以二进制串的形式），返回其二进制表达式中数字位数为 \u0026lsquo;1\u0026rsquo; 的个数。这在数学上被称为计算汉明重量（Hamming Weight）。\n因为汉明重量经常被用于信息论、编码理论和密码学，针对这个问题有多种不同的算法，一些处理器甚至直接带有计算汉明重量的指令，而对于不具备这种特殊指令的普通处理器来说，目前已知效率最高的通用算法就是variable-precision SWAR算法，该算法通过一系列位移和位运算操作，可以在常数时间内计算多个字节的汉明重量，并且不需要使用任何额外的内存。在介绍这个巧妙的算法之前先介绍一些常规算法。\n遍历算法 直接循环检查给定整数n的二进制位的每一位是否是1，这个就不再赘述了。\n查表算法 优化检查操作的一个办法时使用查表法：\n对于一个有限集合来说，集合元素的排列方式是有限的。 而一个有限长度的位数组来说，它能表示的二进制位排列也是有限的。 所以，根据这个原理，我们可以直接创建一个表，表的键为某种排列的位数组，而表的值则是相应位数组中，值为1的二进制位的数量。创建了这种表以后，我们就可以根据输入的位数字进行查表，在无须对位数组的每个位进行检查的情况下，直接知道这个位数组包含了多少个值为1的二进制位。比如说，我们对于8位长的位数组创建表，我们每执行一次查表操作，就可以检查8个二进制位，和之前的遍历算法相比，通过内存的时间换空间策略，查表算法的效率提升了常数倍。\n位运算优化 n \u0026amp; (n - 1)的运算结果可以把n的二进制位中的最低位的1变为0。也就是可以帮我们减少一个1的数量，我们可以利用这个位运算的性质加速我们的检查过程。运算次数等于n的二进制位中1的个数，在最坏情况下，效率会和遍历算法接近。\nvariable-precision SWAR算法 uint32_t swar(uint32_t i) { i = (i \u0026amp; 0x55555555 + ((i \u0026gt;\u0026gt; 1) \u0026amp; 0x55555555)); // 步骤1 i = (i \u0026amp; 0x33333333 + ((i \u0026gt;\u0026gt; 2) \u0026amp; 0x33333333)); // 步骤2 i = (i \u0026amp; 0x0f0f0f0f + ((i \u0026gt;\u0026gt; 4) \u0026amp; 0x0f0f0f0f)); // 步骤3 i = (i*(0x01010101) \u0026gt;\u0026gt; 24); // 步骤4 return i; } 步骤1计算出的值i的二进制表示可以按每两个二进制位为一组进行分组，各组的十进制表示就是该组的汉明重量。 步骤2计算出的值i的二进制表示可以按每四个二进制位为一组进行分组，各组的十进制表示就是该组的汉明重量。 步骤3计算出的值i的二进制表示可以按每八个二进制位为一组进行分组，各组的十进制表示就是该组的汉明重量。 步骤4的i*0x01010101语句计算出bitarray的汉明重量并记录在二进制位的最高八位，通过移位运算将汉明重量移动到最低八位，得出的结果就是bitarray的汉明重量。 swar函数每次执行可以计算32个二进制位的汉明重量，他比之前的遍历算法要快32倍，比键长为8位的查表法快4倍，并且因为swar函数是单纯的计算操作，所以它无需像查表法那样，使用额外的内存。\n","date":"2021-10-11T00:00:00Z","permalink":"https://zjregee.github.io/p/variable-precision-swar%E7%AE%97%E6%B3%95/","title":"variable-precision SWAR算法"},{"content":"最近在写一个KCP的Swift实现，项目在https://github.com/zjregee/kcp-swift，把拥塞窗口去掉了，以及把大量不安全的指针运算用数组高层代替了。或许以后可以考虑在其上实现其他一些版本的拥塞控制和方法\n项目参考了KCP的C源码https://github.com/zjregee/kcp以及一定的Swift版本的https://github.com/rannger/kcp-swift\n介绍一下KCP KCP是基于UDP协议之上的ARQ协议实现。TCP虽然使用的更广泛，但是在某些实时性更高的领域，会更倾向于使用基于UDP的可靠传输协议\nKCP力求在保证可靠性的情况下提高传输速度\nKCP没有规定下层传输协议，但通常使用UDP来实现\n在网络中，我们认为传输是不可靠的，而在很多场景下我们需要的是可靠的数据，所谓的可靠，指的是数据能够正常收到，且能够顺序受到，于是就有了ARQ协议，TCP之所以可靠就是基于此\nARQ协议（Automatic Repeat-reQuest），即自动重传请求，是传输层的错误纠正协议之一，它通过使用确认和超时两个机制，在不可靠的网络上实现可靠的信息传输\n基本特征 RTO不翻倍 选择性重传 快速重传 非延迟ACK TCP在连续ARQ协议中，不会将一连串的每个数据都响应一次，而是延迟发送ACK，目的是为了充分利用带宽，但是这样会计算出较大的RTT时间，延长了丢包时的判断过程，而KCP的ACK是否延迟发送可以调节 UNA+ACK UNA模式参考特征2和特征4，ACK模式可以参考特征3。4字节una表示cmd=81时，当前已经收到了小于una的所有数据 非退让流控 至于通常使用UDP来实现KCP的原因，第一个是UDP的头部相对于TCP的头部来说更小，第二个是KCP相对于TCP来说有太多的冗余功能，这样白白导致了很多不必要的开销\n核心函数 KCP的核心在于四个函数的实现，在这里简单介绍一下四个函数的流程\nikcp_send 检查是否是流模式，需要合并包，将buffer中的数据尽可能的追加到snd_queue中的最后一个报文 计算分片数量 创建多个报文段对象加入snd_queue ikcp_flush 检查ikcp_update是否被调用 将所有ACK报文写入buffer 确定是否需要发送探测报文 检查是否需要发送窗口探测报文，需要的话将报文写入buffer 检查是否需要发送窗口通知报文，需要的话将报文写入buffer 计算拥塞窗口 根据拥塞窗口将数据报文从snd_queue移动到snd_buf 判断快速重传条件，跳过次数以及超时时间 将snd_buf中满足条件的报文都发送出去 将buffer中剩余报文全部发送 根据丢包情况计算ssthresh和cwnd Tips\n发送报文不是将snd_buf中的一一发送，而是必须都先写入buf 在写新报文到buf之前，需要判断buf大小是否过大，将要过大时直接将buf一次性发送 ptr、buffer、snd_queue、snd_buf ikcp_input 循环从收到的data里解包出报文段，为各个字段赋值 调用ikcp_parse_una，根据una将相应已确认送达的报文从snd_buf中删除 调用ikcp_shrink_buf，尝试向右移动snd_una 如果cmd==IKCP_CMD_ACK，即收到了ACK报文 计算RTO 将已确认送达的报文从snd_buf中删除 尝试向右移动snd_una 计算出这次input得到的最大ACK编号 如果cmd==IKCP_CMD_PUSH，即收到了数据报文 调用ikcp_ack_push将相关信息插入ACK列表中 调用ikcp_parse_data，将数据报文插入rcv_buf 在ikcp_parse_data中，会尽可能的将顺序正确的报文移入到rcv_queue中 如果cmd==IKCP_CMD_WASK，标记需要发送窗口通知报文 如果cmd==IKCP_CMD_WINS，什么都不用做，因为wnd字段前面已经取得了 调用ikcp_parse_fastack，检查snd_buf中编号小于maxack且未确认送达的报文，将其fastack加一，说明被跳过了 计算cwnd ikcp_recv 调用ikcp_peeksize，获取rcv_queue中第一个包的大小，因为需要考虑到分片 取出第一个包读入buffer rcv_queue空些了，再尝试从rcv_buf中取些报文到rcv_queue fast recover 拓展阅读 http://kaiyuan.me/2017/07/29/KCP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/ https://www.codedump.info/post/20201105-kcp/ https://luyuhuang.tech/2020/12/09/kcp.html ","date":"2021-10-04T00:00:00Z","permalink":"https://zjregee.github.io/p/kcp%E4%B9%8B%E6%97%85/","title":"KCP之旅"},{"content":"最近开始在实验室做边缘环境下的经典分布式系统算法改进方面的研究，刚开始阅读一篇比较难的论文，读的毫无头绪，被研究生学长推荐了一个读论文的方法，也就是这篇文章http://blizzard.cs.uwaterloo.ca/keshav/home/Papers/data/07/paper-reading.pdf。在这里把这个方法记录下来。\n学习读论文的重要性 在此之前我也看过一些论文，拿到一篇长十几页的论文，我总是从头开始，一句句的看过去，并且由于我的英语并不好，所以不能很好的理解上下文，也经常看到后面就忘记了前面。当这样读完一篇论文后，我的收获并没有那么大，往往只是字面意思的看了一遍。\n想要搞科研的研究人员往往会花费大量的时间去阅读大量的论文，但是大家却很少讨论如何读论文的技能。因此没有经验的人可能会有许多的努力被浪费。所以这篇文章针对这个问题，提出了一个切实可行且高效的方式去阅读论文。\n这让我想起了计算机教育中缺失的一课（https://missing-semester-cn.github.io）\nThe Three-Pass Approach 阅读一篇论文应该分为三个部分，而不是直接从头读到尾。每个部分都会实现具体的目标而且依赖于前面的步骤。\n第一遍让你对这篇论文有一个大致的了解。第二遍让你掌握论文的内容，但不是细节。第三遍帮助你深入了解该论文。\nThe first pass 第一遍是快速扫描，对整个论文框架有一个整体认识，你可以由此决定是否要继续下面的pass。这一遍应该需要大约5到10分钟。\n这些具体的时间都是这篇文章说的，我觉得以我的水平非常非常的的不科学wuwu\n第一遍可以包括以下几个步骤：\n仔细阅读title、abstract以及introduction 仔细阅读每个section以及sub-section的标题，但是忽略其他东西 看一下存在的数学部分，以此确定需要的理论基础 阅读这篇论文的结论 看一下论文的参考部分，寻找是否有你已经读过的资料 完成这一遍后，你应该可以回答下面的5个Cs：\nCategory：这是什么类型的论文？对现有系统的分析？对数据的测量？对研究原型的描述？ Context：它与其他哪些论文有关？用哪些理论基础来分析这个问题？ Correctness：假设是否有效？ Contributions：这篇论文的主要贡献是什么？ Clarity：这篇论文写的好吗，表述清晰吗？ 如果此时你发现你对这篇论文没有兴趣，或者你对这个领域的了解不足以去理解这篇论文，又或者论文作者做出了无效的假设，你可以不继续阅读下去。\n这一遍对于那些不是你研究领域的论文来说是足够的，也可能在未来会被证明是相关的。\nThe second pass 在第二遍时，要更仔细地阅读论文，但可以忽略诸如证明等细节问题。在阅读过程中，可以记下关键点，或在空白处做评论，这会对阅读起到帮助。\n仔细阅读论文中的数字、图表和插图。可以注意论文的图表是否有细节处的常见错误 记得标记相关的还没有阅读过的参考文献，以便之后可以进一步阅读，也可以让你对论文背景更好的了 对于一个有经验的读者来说，第二遍应该花上一个小时。经过这次阅读，你应该能够掌握论文的内容，向其他人总结论文的主旨，并提供支持性证据。这种详细程度已经适合于你感兴趣的论文，但对于属于你研究专长的论文还需进一步深入。\n有时，即使在第二遍结束时，你也无法理解一篇论文。这可能是因为该主题对你来说是新的，有不熟悉的术语和缩略语，或者作者可能使用了你不理解的证明或实验技术，所以论文的大部分内容是无法理解的。论文可能写得很差，没有事实依据的断言和大量的转发引用。也可能只是因为现在是深夜，你很累。你现在可以选择：\n把论文放在一边，希望你不需要了解这些内容就能在事业上获得成功 以后再看这篇论文，也许是在阅读更多的背景材料之后 坚持下去，进入第三遍 The third pass 要完全理解一篇论文，需要第三遍。第三遍的关键在于尝试虚拟地重新实现该论文：也就是说，在与作者做出相同假设的前提下，去理解并重新实现/创造该工作。通过这种比较再现和实际的论文，你不仅可以很容易的发现该论文的创新之处，甚至发现其中隐藏的问题和假设。\n这一遍需要非常注意细节，你应该找出并挑战每一个提到的假设。此外，你还可以思考如果是你，你会如何陈述这个特定的想法。在这个过程中，你还可以记下对未来工作的想法。\n这一遍对于初学者来说可能需要非常多的时间。如果完成了这一步，你应该能够根据记忆重建论文的整合结构，确定其强项和缺点，甚至指出隐含的假设、缺少的对相关工作的引用以及实验或分析技术可能存在的问题。\n最后这篇文章还介绍了在做文献调查可能需要在不熟悉的领域阅读数十篇论文时可以采用的具体方法，该兴趣的可以直接去看这篇文章。\n","date":"2021-09-29T00:00:00Z","permalink":"https://zjregee.github.io/p/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E7%AF%87%E8%AE%BA%E6%96%87/","title":"如何阅读一篇论文"},{"content":"这篇文章将对lock-free编程进行一个简单介绍。\n什么是lock-free 维基百科是这样解释的，lock-free的同义词是Non-blocking algorithm。\nIn computer science, an algorithm is called non-blocking if failure or suspension of any thread cannot cause failure or suspension of another thread; for some operations, these algorithms provide a useful alternative to traditional blocking implementations. A non-blocking algorithm is lock-free if there is guaranteed system-wide progress, and wait-free if there is also guaranteed per-thread progress. \u0026ldquo;Non-blocking\u0026rdquo; was used as a synonym for \u0026ldquo;lock-free\u0026rdquo; in the literature until the introduction of obstruction-freedom in 2003.\nLock-free编程指利用一组特定的原子操作来控制多个线程对于同一数据的并发访问。相比于基于锁的算法，Lock-free的一个明显特征：某个线程在执行数据访问时挂起不会阻碍其他的线程继续执行。\nCAS CAS即Compare-and-Swap，是一种实现并发算法时常用的技术。大部分lock-free的算法都是通过CAS操作实现的。\nCAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。\nCAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。\n如何实现一个lock-free队列 队列是非常常用的数据结构，而在并发环境中使用队列，就必须考虑到多线程并发读写的问题。虽然我们可以通过一个互斥锁简单的实现队列的并发访问，因为互斥锁保护的临界区并没有很复杂的执行逻辑，所以临界区的处理也很快，一般情况下，这样通过互斥锁实现队列的效率已经很高了。但是在一些情况下，通过实现lock-free算法，可以进一步提高并发队列的性能。\nhttps://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf这篇1996年的论文就已经提出了lock-free queue算法的简洁实现，并且还提供了一个在特定机器比如不存在CAS指令的机器上的two-lock queue算法。\nlock-free queue伪代码实现\nstructure pointer_t {ptr: pointer to node_t, count: unsigned integer} structure node_t {value: data type, next: pointer_t} structure queue_t {Head: pointer_t, Tail: pointer_t} initialize(Q: pointer to queue_t) node = new_node() node-\u0026gt;next.ptr = NULL Q-\u0026gt;Head.ptr = Q-\u0026gt;Tail.ptr = node enqueue(Q: pointer to queue_t, value: data type) E1: node = new_node() E2: node-\u0026gt;value = value E3: node-\u0026gt;next.ptr = NULL E4: loop E5: tail = Q-\u0026gt;Tail E6: next = tail.ptr-\u0026gt;next E7: if tail == Q-\u0026gt;Tail E8: if next.ptr == NULL E9: if CAS(\u0026amp;tail.ptr-\u0026gt;next, next, \u0026lt;node, next.count+1\u0026gt;) E10: break E11: endif E12: else E13: CAS(\u0026amp;Q-\u0026gt;Tail, tail, \u0026lt;next.ptr, tail.count+1\u0026gt;) E14: endif E15: endif E16: endloop E17: CAS(\u0026amp;Q-\u0026gt;Tail, tail, \u0026lt;node, tail.count+1\u0026gt;) dequeue(Q: pointer to queue_t, pvalue: pointer to data type): boolean D1: loop D2: head = Q-\u0026gt;Head D3: tail = Q-\u0026gt;Tail D4: next = head.ptr-\u0026gt;next D5: if head == Q-\u0026gt;Head D6: if head.ptr == tail.ptr D7: if next.ptr == NULL D8: return FALSE D9: endif D10: CAS(\u0026amp;Q-\u0026gt;Tail, tail, \u0026lt;next.ptr, tail.count+1\u0026gt;) D11: else D12: *pvalue = next.ptr-\u0026gt;value D13: if CAS(\u0026amp;Q-\u0026gt;Head, head, \u0026lt;next.ptr, head.count+1\u0026gt;) D14: break D15: endif D16: endif D17: endif D18: endloop D19: free(head.ptr) D20: return TRUE 在这里说明几个重要的点:\nE7的目的是判断此时是否有其他线程加入了别的节点，有的话重新获取 E8可能一开始比较难理解，但因为完整的入队流程分为两部，加入新结点，将尾节点后移，所以在判断E7的基础上存在目前的尾节点并不是Q-\u0026gt;Tail的情况，即别的线程只加入了新结点，没有把Q-\u0026gt;Tail后移。所以还需进行一个if判断，如果next.ptr == NULL为true，则说明目前确实没有别的线程加入了别的节点，直接进行CAS语句插入节点在尾部 E13的目的是帮助把尾指针移动到被其他线程插入的节点 E17的目的在于完成入队操作后，将队列的尾指针指向新插入的节点。这里没有循环，所以CAS操作是可能不成功的，即此时在别的线程又有新的节点加入了，但是这并没有关系，因为这个节点已经加入了队列，只不过他已经不是尾节点了而已。更新加入的节点的逻辑会移动尾节点到最后的新加入的节点上 D5判断此时是否有其他线程正在进行出队，有的话则重新获取 D6对队列的头指针和尾指针进行判断，如果相等说明有两种情况，可能是空队列，没有数据可以出队，直接返回false，还有可能是入队操作已经加入了节点但还没有移动尾指针，所以帮助移动后重新获取数据 D12获取数据的操作在CAS操作之前，这其实是有考虑的，因为数据并不是保存在第一个节点，第一个节点不保存数据或者说数据没有任何用，只是一个辅助的头节点。出队的数据在第二个节点，如果CAS操作之后再获取数据，存在另一个线程的出队操作在CAS操作和获取数据之间释放掉这个节点的可能性 D19直接释放旧节点，只时候已经完成出队操作，可以安全释放 拓展概念 RMW COW RCU Hazard Pointer lock-free map ABA问题 内存屏障 多核无锁编程 参考资料 https://colobu.com/2020/08/14/lock-free-queue-in-go/\nhttp://kaiyuan.me/2017/12/14/lock-free-prog1/\nhttp://kaiyuan.me/2018/02/07/lock-free-prog2/\nhttps://mp.weixin.qq.com/s?__biz=MzkyMTIzMTkzNA==\u0026mid=2247524195\u0026idx=1\u0026sn=55d35a8e2b737505a2f6992a35e0648f\u0026chksm=c1846832f6f3e124c355bbb13098d564f0f9570c3155ba9462aa7e886e50630902b1a20dfc8a\u0026scene=132#wechat_redirect\nhttps://segmentfault.com/a/1190000022798961\nhttps://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf\nhttps://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook-e2.pdf\n","date":"2021-09-28T00:00:00Z","permalink":"https://zjregee.github.io/p/lock-free-programming/","title":"lock-free programming"},{"content":"A Bitcask instance is a directory, and we enforce that only one operationg system process will open that Bitcask for writing at a given time.\nAt any moment, one file is active in that directory for writing by the server. When that file meets a size threshold it will be closed and a new active file will be created.\nOnce a file is closed, either purposefully or due to server exit, it is considered immutabele and will never opened for writing again. The active file is only written by appending, which means that sequential writes do not require disk seeking.\nThe format that is written for each key/value entry is simple.\nWith each write, a new entry is appended to the active file. Note that detetion is simply a write of a special tombstone value, which will be removed on the next merge. Thus, a Bitcask data file is nothing more than a linear sequence of these entries.\nAfter the append completes, an in-memory structure called a keydir is updated. A keydir is simply a hash table that maps every key in a Bitcask to a fixed-size structure giving the file, offset, and size of the most recently written entry for that key.\nWhen a write occurs, the keydir is atomically updated with the location of the newest data. The old data is still present on disk, but any new reads will use the latest version available in the keydir. The merge process will eventually remove the old value.\nReading a value is simple, and doesn\u0026rsquo;t ever require more than a single disk seek. We look up the key in our keydir, and from there we read the data using the file_id, position, and size that are returned from that lookup. In many case, the operation system\u0026rsquo;s filesystem read-ahead cache makes this a much faster operation than would be otherwise expected.\nThe merge process iterates over all non-active files in a Bitcask and produces as output a set of data files containing only the \u0026ldquo;live\u0026rdquo; or latest versions of each present key.\nWhen this is done we also create a hint file next to each data file. These are essentially like the data files but instead of the values they contain the position and size of the values within the corresponding data file.\nWhen a Bitcask is opened by an Erlang process, it checks to see if there is already another Erlang process in the same VM that is using that Bitcask. If so, it will share the keydir with that process. If not, it scans all of the data files in a directory in order to build a new keydir. For any data file that has a hint file, that will be scanned instead for a much quicker startup time.\nThese basic operation are the essence of the bitcask system.\n","date":"2021-09-10T00:00:00Z","permalink":"https://zjregee.github.io/p/bitcask%E5%AE%9E%E7%8E%B0%E7%AE%80%E4%BB%8B/","title":"Bitcask实现简介"},{"content":"文件系统概述 在详细介绍FAT文件系统之前，我们先简单介绍一下 在Windows中比较常用的三种分区和卷管理的文件系统。\nFAT概述 FAT文件系统的特点是文件分配表（FAT），他实际上是一个位于卷的“顶部”的表。为了保护卷，FAT的两个副本被保存起来，以防止一个被损坏。此外，FAT表和根目录必须存储在一个固定的位置，以便系统的启动文件能够被正确定位。\n用FAT格式化的磁盘被分配在簇中，其大小由卷的大小决定。当一个文件被创建时，会在目录中创建一个条目，并建立包含数据的第一个簇号。FAT表中的这个条目要么表明这是文件的最后一个簇，要么指向下一个簇。\nFAT的优点\nFAT是目前应用最为广泛和获得操作系统支持最多的一种磁盘分区格式，几乎所有的操作系统都支持这一种格式。\nFAT的缺点\n在使用超过200MB的驱动器或分区时，不应使用FAT文件系统。这是因为随着卷大小的增加，FAT的性能将快速降低。无法对属于FAT分区的文件设置权限。\nFAT分区的大小在Windows NT下被限制在最大4GB，在MS-DOS下被限制在2GB。\n更新FAT表是非常重要的，也是非常耗时的。如果FAT没有定期更新，就会导致数据丢失。它很耗时，因为每次更新FAT表时，磁盘读头必须被重新定位到驱动器的逻辑轨道0。\nHPFS 概述 HPFS文件系统的出现源于对当时市场上出现的较大的硬盘进行访问的允许。此外，为了满足网络服务器市场日益增长的需求，有必要采用新的文件系统来扩展命名系统、组织和安全性。HPFS保持了FAT的目录组织，但增加了基于文件名的目录的自动排序。此外，分配的单元从簇改为物理扇区，这减少了磁盘空间的损失。\nHPFS的缺点\n由于HPFS所涉及的开销，对于一个小于200MB的卷来说，它不是一个非常有效的选择。此外，对于大于400MB的卷，会有一些性能下降。你不能在Windows NT下为HPFS设置安全。\nHPFS只在Windows NT 3.1、3.5和3.51版本下被支持。Windows NT 4.0 不能访问 HPFS 分区。\nNTFS 概述 NTFS是Microsoft公司开发的专用文件系统，从Widows NT 3.1开始称为Windows NT家族的默认文件系统。NTFS取代FAT和HPFS并进行一系列改革改进成为更加完善的安全系统，例如增强对元数据的支持，使用更高级的数据结构以提升性能、可靠性和磁盘空间利用率，并附带一系列增强功能。\n上面是对三种文件系统的一个大致介绍，可能有点宽泛，接下来我们依据微软提供的官方文档具体看一下FAT的细节与实现。\nFAT细节 首先是一些基本概念\nbyte\n作为一个单元操作的一串二进制数字\nfile\n一个命名的字节流，代表一个信息的集合\nsector\n一个数据单位，可以独立于其他单位被访问\ncluster\n一个由一组逻辑上连续的扇区组成的分配单元。卷内的每个簇都用簇号N来表示。一个文件的所有分配都必须是一个簇的整数倍\npartion\n一个卷内一些簇组成的的一个范围\nvolume\n磁盘上的一个存储区域\n磁盘上的FAT格式有三种：\nFAT12 FAT16 FAT32 卷的结构 一个FAT文件系统的卷是由四个基本区域组成的，它们在卷上是按以下顺序排列的\n第一个是保留区域，第二个是FAT区域，第三个是根目录区域（在FAT32卷中不存在），第四个是文件和目录数据区域。\n所有的FAT文件系统最初都是为IBM PC机器结构开发的。因此，磁盘上的FAT格式的数据结构都是little endian。\n出现了一个新的名词，什么是little endian？\nBig Endian认为第一个字节是最高位字节（按照从低地址到高地址的顺序存放数据的高位字节到低位字节），而Little Endian则相反，他认为第一个字节是最低位字节\nBoot Sector 和 BPB BPB（BIOS参数块）位于卷中保留区域的第一个扇区中。这个扇区有时被称为启动扇区或第0扇区。这个扇区是卷的第一个扇区。\n所有FAT卷都必须在启动扇区有一个BPB。\n所以BPB是存储在Boot Sector中的数据，那么BPB是存了哪些数据呢？\n举几个比较关键的fields：\nDescriptive name of field Offset(byte) Size(bytes) Description BS_jmpBoot 0 3 跳转到操作系统引导启动代码的指令。这段代码通常占据了BPB之后的卷内0号扇区的其余部分，可能还有其他扇区 BPB_BytsPerSec 11 2 每个扇区的字节数：512、1024、2048、4096 BPB_SecPerClus 13 1 每个簇的扇区数 BPB_RsvdSecCnt 14 2 从卷的第一个扇区开始，卷的保留区域中的保留扇区的数量 BPB_NumFATs 16 1 The count of file allocation tables (FATs) on the volume BPB_RootEntCnt 17 2 对于FAT12和FAT16卷，这个字段包含根目录中32字节的目录条目计数。对于FAT32卷，这个字段必须设置为0 BPB_TotSec16 19 2 这个字段是卷上16位的扇区总数。这个计数包括卷的所有四个区域的所有扇区的计数。这个字段可以是0；如果它是0，那么BPB_TotSec32必须是非零。对于FAT32卷，这个字段必须是0 BPB_FATSz16 22 2 这个字段是FAT12/FAT16由一个FAT占用的16位扇区数。在FAT32卷上，这个字段必须是0，BPB_FATSz32包含FAT大小计数 BPB_TotSec32 32 4 这个是卷上32位的扇区总数。对于FAT32卷，这个字段必须是非0 BPB_FATSz32 36 4 这个字段是FAT32有一个FAT占用的32位的扇区数 从offset 36开始，FAT12和FAT16的BPB/boot扇区与FAT32的BPB/boot扇区不同\nFAT FAT（File Allocation Table 文件分配表）中的每个有效条目表示由根目录区域（如果有）和文件和目录数据区域组成的簇集合中的簇状态。\n每一个条目的大小：\n对于FAT12的卷，每个FAT条目12位 对于FAT16的卷，每个FAT条目16位 对于FAT32的卷，每个FAT条目32位 FAT 定义了一个文件的\u0026quot;extents\u0026quot; (clusters)的单链表，并和数据区域通过簇号形成对应的关系。第一个数据簇在卷中的编号是#2。\n目录结构 FAT目录是一种特殊的文件类型。该目录作为其他文件和子目录的容器。目录内容（数据）是一系列32字节的目录条目。每个目录条目依次代表一个包含的文件或子目录的目录。\n下面是一个32字节目录条目中比较重要的一些字段\nDescriptive name of field Offset(byte) Size(bytes) Description DIR_Name 0 11 8.3格式存储的最多11个字符的文件短名字 Dir_Attr 11 1 文件属性类型定义 DIR_CrtTime 14 2 创建时间。颗粒度是2秒 DIR_CrtDate 16 2 创建日期 DIR_LstAccDate 18 2 上一次访问日期 DIR_FstClusHI 20 2 此条目所描述的文件/目录的第一个数据簇号的高字部分 DIR_FstClusLO 26 2 此条目所描述的文件/目录的第一个数据簇号的低字部分 DIR_FileSize 28 4 32位的文件大小（以字节为单位） ","date":"2021-07-18T00:00:00Z","permalink":"https://zjregee.github.io/p/fat%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/","title":"FAT文件系统介绍"},{"content":"MapReduce: Simplified Data Processing on Large Clusters Abstract MapReduce是一个编程模型和一个相关的实现，用于处理和生成大型数据集。用户指定一个map函数来处理一个键/值对，生成一组中间键/值对，并指定一个reduce函数来合并与同一中间键相关的所有中间值。许多现实世界的任务都可以用这个模型来表达，以这种函数式编写的程序被自动并行化，并在一个大型的组合机集群上执行。运行时系统负责分割输入数据的细节，在一组机器上调度程序的执行，处理机器故障，以及管理所需的机器间通信。这使得没有任何并行和分布式系统经验的程序员可以轻松地利用大型分布式系统的资源。\nIntroduction Google中的许多人使用MapReduce实现了数百种特殊用途的计算，这些计算处理了大量的原始数据，如抓取的文件、网络请求日志等，以计算各种衍生数据。大多数这样的计算在概念上是直接了当的。然而，输入的数据通常很大，计算必须分布在数百或数千台机器上，以便在合理的时间内完成。如何对计算进行分工，分配数据，以及处理故障等这些问题，会用大量复杂的代码掩盖最初的简单计算。\n为了处理这种复杂性，设计了一个新的抽象，它允许我们表达我们试图执行的简单计算，但将并行化、容错、数据分配和负载平衡等混乱的东西隐藏在一个库中。所以，MapReduce的主要贡献是一个简单而强大的接口，能够实现大规模计算的自动并行化和分布以及在大型商用PC集群上的高性能。\nProgrmaming Model 该计算接受一组输入键/值对，并产生一组输出键/值对。MapReduce库的用户将计算表达为两个函数，map和reduce。\n由用户编写的map函数需要一个输入对，并产生一组中间键/值对。MapReduce库将所有与同一中间键I相关的中间值分组，并将它们传递给reduce函数。reduce函数同样是由用户编写的，它接受一个中间值I和该键的一组值。它将这些值合并起来，形成一个可能更小的值集。一般来说，每次reduce调用只产生0或1个输出值。中间值通过一个迭代器提供给用户的reduce函数。这使得我们能够处理那些大到无法在内存中容纳的数值列表。\n举个🌰 考虑这样一个问题：在一大批文件中计算每个词的出现次数的问题。\n用户可以编写这样的map、reduce函数伪代码：\nmap(String key, String value): // key: document name // value: document contents for each word w in value: EmitIntermediate(w, \u0026#34;1\u0026#34;); reduce(String key, Iterator values): // key: a word // values: a list of coutns int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); map函数给出每个单词和相关的出现次数（在这个简单的例子中只有“1”）。reduce函数将map为某一特定单词给出的所有计数相加。\n用户在使用MapReduce库时可以编写代码来填写mapreduce中规范的对象（包括输入和输出文件的名称，以及可选的调整参数），然后调用相应函数把规范对象传递给它。\nTypes 理论上，用户提供的map和reduce函数应该具有如下相关联的类型：\nmap (k1, v1) -\u0026gt; list(k2, v2) reduce (k2, list(v2)) -\u0026gt; list(v2) 输入的键和值来自与输出键和值不同的域，中间键和值与输出键和值来自同一个域。\nImplementation ![截屏2021-06-10 上午11.02.02](/Users/yurunjie/Library/Application Support/typora-user-images/截屏2021-06-10 上午11.02.02.png)\n可能会有多种关于MapReduce接口的实现，具体对于实现的选择取决于环境，每种实现可能适合其对应的环境要求和限制。接下来的部分描述了一个在Google中广泛使用的计算环境的实现。\nExecution Overview 通过将输入数据自动划分为M个分割集，从而map调用可以被分布在多个机器上。输入的分割集可以由不同的机器并行处理。reduce调用是通过使用一个分区函数（例如：hash(key)mod R）将中间键空间划分为R个块来进行分配的。分区的数量R和分区函数可以由用户指定。\nFigure1显示了我们这里MapReduce实现的一个整体流程。根据图中的()标号进行对应的解释：\n(1) 用户程序中的MapReduce库首先将输入文件分割成M块，每块通常为16MB到64MB（用户可通过一个可选参数进行控制）。然后，他在一组机器上fork启动许多程序的副本。 (2) 其中的一个特殊的副本被称为master。其他副本是由master来分配任务的worker。这里有M个map任务以及R个reduce任务需要分配。master选择空闲的workers并给他们每人分配一个map任务或者reduce任务。 (3) 一个被分配map任务的worker读取相应输入分割集的内容。它从输入数据中解析键/值对，并将每个键/值对传递给用户对应的map函数。map函数产生的中间键/值对被缓冲在内存中。 (4) 缓存对定期写入本地磁盘，由分区函数划分为R个区域。这些缓冲对在本地磁盘上的位置被传递给主服务器，主服务器负责将这些位置转发给负责reduce任务的worker。 (5) 当master通知负责reduce worker这些位置时，这些worker使用RPC远程调用从map worker的本地磁盘读取缓冲数据。当reduce worker读取了所有中间数据后，他就会根据中间键对数据进行排序，以便所有出现的相同键都被分组在一起。如果中间数据量太大，无法装入内存，则使用外部排序。 (6) reduce worker遍历已排序的中间数据，对于遇到的每个唯一的中间键，它将键和相应的中间值集传递给用户的reduce函数。reduce函数的输出被添加到这个reduce部分的最终输出文件中。 当所有的map和reduce任务都完成后，master唤醒用户程序。此时，用户程序中的MapReduce调用返回给用户代码。 MapReduce成功执行后的输出再R个输出文件中（每个reduce任务一个，文件名由用户指定）。通常，用户不需要将这R个输出文件合并到一个文件中——他们经常将这些文件作为输入传递给另一个MapReduce调用，或者在另一个分布式应用程序中使用它们，该应用程序能够处理划分为多个文件的输入。\nMaster Data Structures master保留了几个数据结构。对于每个map、reduce任务，它都存储了状态以及woker机器的身份。master将中间文件区域的位置从map任务传递到reduce任务。因此，对于每个完成的map任务，主服务器存储由map任务产生的R个中间文件区域的位置和大小。当完成map任务后，master将接收到对该位置和大小信息的更新。这些信息以增量的方式推送给正在进行reduce任务的worker。\nFault Tolerance 因为MapReduce库被设计为使用成百上千台机器帮助处理非常大量的数据，所以该库必须处理好机器故障等情况的出现。\nWorker Failure\nmaster定时ping每个worker。如果在一定时间内没有收到某个worker的回复，master就会给这个worker标记为failed。这个woker完成或正在进行的的任何map任务都会重置为最初的闲置状态，从而在其他worker进行重新调度。\n已完成的map任务在机器出现故障时都要重新执行，因为他们的输出被存储在故障机器的本地磁盘上，因此无法访问。已完成的reduce任务不需要重新执行，因为他们的输出被存储在全局文件系统中。\n当一个map任务先由worker A执行，然后再由worker B执行（因为A失败了），所有执行reduce任务的worker都会被通知重新执行。任何尚未从工作者A处读取数据的还原任务将从工作者B处读取数据。\nMapReduce可以容忍大规模的工作机器故障。\nMaster Failure\nIt is easy to make the master write periodic checkpoints of the master data structures described above. If the master task dies, a new copy can be started from the last checkpointed state. 但是，考虑到只有一个master，如果master失败了。现在的实现就会终止MapReduce计算。客户端可以检查这种情况，如果他们愿意，可以重试MapReduce操作。\nLocality 网络带宽在我们的计算环境中是一种相对稀缺的资源。我们通过输入数据（由GFS管理）存储在组成我们集群的机器的本地磁盘这一事实来节约网络带宽。GFS将每个文件分成64MB的块，并在不同的机器上存储每个块的多个副本（通常是3个副本）。MapReduce主程序考虑输入文件的位置信息，并尝试在包含相应输入数据副本的机器上调度map任务。如果做不到这一点，它就尝试在任务输入数据的副本附近调度一个map任务。当在集群中相当一部分worker运行大型MapReduce操作时，大多数输入数据都是在本地读取的，不会消耗网络带宽。\nTask Granularity 像之前说的那样，我们将map阶段细分为M个任务，将reduce阶段细分为R个任务。理想情况下，M和R应该远远大于worker的数量。让每个worker执行许多不同的任务可以改善动态负载平衡，也可以在一个工作者失败时加速恢复：他所完成的许多map任务可以分散到所有其他woker上。\n在我们的实现中，对M和R的大小是有实际限制的，因为master必须做出O(M+R)的调度决定，并在内存中保持O(M*R)的状态（尽管，内存使用的因素影响很小）。\nR同时也经常收到用户的限制，因为每个reduce任务的输出最终都在一个单独的输出文件中。在实践中，我们倾向于选择M，使每个单独的任务大约是16 MB到64 MB的输入数据（以便上述的locality优化最有效），并让R变成我们期望使用的worker数量的很小的倍数。我们经常在M=200,000和R=5,000的情况下进行MapReduce计算，使用2,000台工作机。\nBackup Tasks 使得MapReduce操作总时间变长的常见原因之一是出现了“掉队者”：一台机器花了异常长的时间来完成计算中的最后几个map或reduce任务中的某个。“掉队者”出现的原因有很多：一台有坏磁盘的机器可能经常出现可纠正的错误，使其读取性能降低；集群调度系统可能在机器上安排了其他任务，由于对CPU、内存、本地磁盘或网络带宽的竞争，导致它执行MapReduce代码的速度变慢。\n我们有一个通用的机制来缓解掉队的问题。当MapReduce操作接近完成时，主系统会调度剩余正在执行的任务的备份执行。当主执行或备份执行完成时，任务被标记为完成。我们已经对这种机制进行了调优，因此它通常会将操作使用的计算资源增加不超过几个百分点。我们发现这大大减少了完成大型MapReduce操作的时间。\nConclusions MapReduce编程模型已经在谷歌成功地用于许多不同的目的。这一成功归结于几个原因。首先，该模型易于使用，即使对没有并行和分布式系统经验的程序员也是如此，因为它隐藏了并行化、容错、局部优化和负载平衡的细节。第二，大量的问题可以很容易地用MapReduce计算来表达。第三，我们开发了一个MapReduce的实现，它可以拓展到由数千台机器组成的大型机器集群。该实现有效地利用了这些机器资源，因此适用于在谷歌遇到的许多大型计算问题。\n我们从这项工作中学到了一些东西。首先，限制编程模型可以使计算易于并行化和分布，并使此类计算具有容错性。其次，网络带宽是一种稀缺资源。因此，我们系统中的许多优化都以减少通过网络发送的数据量为目标：局部优化允许我们从本地本地磁盘读取数据，并将中间数据的单个副本写入本地磁盘节省网络带宽。第三，冗余执行可以减少机器慢速的影响，处理机器故障和数据丢失。\n上述内容来自于对mapreduce论文的整理\nhttps://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf\n","date":"2021-05-29T00:00:00Z","permalink":"https://zjregee.github.io/p/simplified-data-processing-on-large-clusters/","title":"Simplified Data Processing on Large Clusters"},{"content":"默认情况下，Swift会阻止你代码里不安全的行为。例如，Swift会保证变量在使用之前就完成初始化，在内存被回收之后就无法被访问，并且数组的索引会做越界检查\nSwift也保证同时访问同一块内存时不会冲突，通过约束代码里对于存储地址的写操作，去获取那一块内存的访问独占权。因为Swift自动管理内存，所以大部分时候你完全不需要考虑内存访问的事情。然而，理解潜在的冲突也是很重要的，可以避免你写出冲突的代码。而如果你的代码确实存在冲突，那在编译时或者运行时就会得到错误\n理解内存访问冲突 内存的访问，会发生在你给变量赋值，或者传递参数给函数时\n下面的代码就包含了读和写的访问\n// 向one所在的内存区域发起一次写操作 var one = 1 // 向one所在的内存区域发起一次读操作 print(\u0026#34;We\u0026#39;re number \\(one)!\u0026#34;) 内存访问的冲突会发生在你的代码尝试同时访问同一个存储地址的时候。同一个存储地址的多个访问同时发生会造成不可预计或不一致的行为。在Swift里，有很多修改值的行为都会持续好几行代码，在修改值的过程中进行访问是有可能发生的\n如果你写过并发和多线程的代码，内存访问冲突也许是同样的问题。然而，这里访问冲突的讨论是在单线程的情景下讨论的，并没有使用并发或者多线程\n如果你曾经在单线程代码里有访问冲突，Swift可以保证你在编译或者运行时会得到错误。对于多线程的代码，可以使用Thread Sanitizer去帮助检测多线程的冲突\nThread Sanitizer Thread Sanitizer是基于LLVM的适用于Swift和C语言的检测数据竞争的工具\n当多个线程在非同步的情况下访问同一内存且至少有一个是写操作时，就会发生数据竞争。数据竞争是非常危险的，可能导致程序的行为无法预测，甚至导致内存损坏。Thread Sanitizer还可以检测其他类型线程错误，包括未初始化的互斥锁和线程泄漏\nThread Sanitizer的原理\n记录每一个内存访问的信息，并检测该访问是否参与竞争。代码中所有的内存访问都会被编译器转换为如下形式\n// Before *address = ...; // or: ... = *address; // After RecordAndCheckWrite(address); *address = ...; // or: ... = *address; 对性能的影响\n开启Thread Sanitizer，将使代码执行效率降低2-20倍，内存使用增加5-10倍。可以通过设置-01优化级别来提高内存利用率\n如何开启Thread Sanitizer\nThread Sanitizer\n数据多线程访问 访问未初始化的锁 线程使用完未释放 内存访问性质 内存访问冲突时，要考虑内存访问上下文中的这三个性质：访问是读还是写，访问的时长，以及被访问的存储地址。特别是，冲突会发生在当你有两个访问符合下列的情况\n至少有一个写访问 他们访问的是同一个存储地址 他们的访问在时间线上部分重叠 读和写访问的区别很明显：一个写访问会改变存储地址，而读操作不会。存储地址是指向正在访问的东西的位置的值。内存访问的时长要么是瞬时的，要么是长期的\n如果一个访问不可能在其访问期间被其他代码访问，那么就是一个瞬时访问。正常来说，两个瞬时好访问是不可能同时发生的。大多数内存访问都是瞬时的\nfunc oneMore(than number: Int) -\u0026gt; Int { return number + 1 } var myNumver = 1 myNumber = oneMore(than: myNumber) print(myNumber) 然而，有几种被称为长期访问的内存访问方式，会在别的代码执行时持续进行。瞬时访问和长期访问的区别在于别的代码有没有可能在访问期间同时访问，也就是在时间线上的重叠。一个长期访问可以被别的长期访问或瞬时访问重叠\n典型的访问主要出现在使用in-out参数的函数和方法或者结构体的mutating方法里\nIn-Out参数的访问冲突 一个函数会对它所有的 in-out 参数进行长期写访问。in-out 参数的写访问会在所有非 in-out 参数处理完之后开始，直到函数执行完毕为止。如果有多个 in-out 参数，则写访问开始的顺序与参数的顺序一致\n长期访问的存在会造成一个结果，你不能在访问以 in-out 形式传入后的原变量，即使作用域原则和访问权限允许——任何访问原变量的行为都会造成冲突\nvar stepSize = 1 func increment(_ number: inout Int) { number += stepSize } increment(\u0026amp;stepSize) // 错误：stepSize 访问冲突 // error: Execution was interrupted, reason: signal SIGABRT. stepSize的读访问和number的写访问重叠了发生了冲突\n解决这个冲突的一种方式，是显式拷贝一份stepSize\n// 显式拷贝 var copyOfStepSize = stepSize increment(\u0026amp;copyOfStepSize) // 更新原来的值 stepSize = copyOfStepSize // stepSize 现在的值是 2 读访问在写操作之前就已经结束了，所以不会有冲突\n长期写访问的存在还会造成另一种结果，往同一个函数的多个 in-out 参数里传入同一个变量也会产生冲突\nfunc balance(_ x: inout Int, _ y: inout Int) { let sum = x + y x = sum / 2 y = sum - x } var playerOneScore = 42 var playerTwoScore = 30 balance(\u0026amp;playerOneScore, \u0026amp;playerTwoScore) // 正常 balance(\u0026amp;playerOneScore, \u0026amp;playerOneScore) // 错误：playerOneScore 访问冲突 发起两个写访问，同时访问同一个的存储地址\n注意\n因为操作符也是函数，他们也会对in-out参数进行长期访问\n方法里Self的访问冲突 一个结构体的 mutating 方法会在调用期间对 self 进行写访问\nstruct Player { var name: String var health: Int var energy: Int static let maxHealth = 10 mutating func restoreHealth() { health = Player.maxHealth } } 在上面的 restoreHealth() 方法里，一个对于 self 的写访问会从方法开始直到方法 return。在这种情况下，restoreHealth() 里的其它代码不可以对 Player 实例的属性发起重叠的访问。下面的 shareHealth(with:) 方法接受另一个 Player 的实例作为 in-out 参数，产生了访问重叠的可能性\nextension Player { mutating func shareHealth(with teammate: inout Player) { balance(\u0026amp;teammate.health, \u0026amp;health) } } var oscar = Player(name: \u0026#34;Oscar\u0026#34;, health: 10, energy: 10) var maria = Player(name: \u0026#34;Maria\u0026#34;, health: 5, energy: 10) oscar.shareHealth(with: \u0026amp;maria) // 正常 上面的例子里，调用 shareHealth(with:) 方法去把 oscar 玩家的血量分享给 maria 玩家并不会造成冲突。在方法调用期间会对 oscar 发起写访问，因为在 mutating 方法里 self 就是 oscar，同时对于 maria 也会发起写访问，因为 maria 作为 in-out 参数传入。过程如下，它们会访问内存的不同位置。即使两个写访问重叠了，它们也不会冲突\n当然，如果你将 oscar 作为参数传入 shareHealth(with:) 里，就会产生冲突\noscar.shareHealth(with: \u0026amp;oscar) // 错误：oscar 访问冲突 mutating 方法在调用期间需要对 self 发起写访问，而同时 in-out 参数也需要写访问。在方法里，self 和 teammate 都指向了同一个存储地址——就像下面展示的那样。对于同一块内存同时进行两个写访问，并且它们重叠了，就此产生了冲突\n属性的访问冲突 如结构体，元组和枚举的类型都是由多个独立的值组成的，例如结构体的属性或元组的元素。因为它们都是值类型，修改值的任何一部分都是对于整个值的修改，意味着其中一个属性的读或写访问都需要访问整一个值。例如，元组元素的写访问重叠会产生冲突\nvar playerInformation = (health: 10, energy: 20) balance(\u0026amp;playerInformation.health, \u0026amp;playerInformation.energy) // 错误：playerInformation 的属性访问冲突 上面的例子里，传入同一元组的元素对 balance(_:_:) 进行调用，产生了冲突，因为 playerInformation 的访问产生了写访问重叠。playerInformation.health 和 playerInformation.energy 都被作为 in-out 参数传入，意味着 balance(_:_:) 需要在函数调用期间对它们发起写访问。任何情况下，对于元组元素的写访问都需要对整个元组发起写访问。这意味着对于 playerInfomation 发起的两个写访问重叠了，造成冲突\n下面的代码展示了一样的错误，对于一个存储在全局变量里的结构体属性的写访问重叠了\nvar holly = Player(name: \u0026#34;Holly\u0026#34;, health: 10, energy: 10) balance(\u0026amp;holly.health, \u0026amp;holly.energy) // 错误 在实践中，大多数对于结构体属性的访问都会安全的重叠。例如，将上面例子里的变量 holly 改为本地变量而非全局变量，编译器就会可以保证这个重叠访问是安全的\nfunc someFunction() { var oscar = Player(name: \u0026#34;Oscar\u0026#34;, health: 10, energy: 10) balance(\u0026amp;oscar.health, \u0026amp;oscar.energy) // 正常 } 编译器可以保证内存安全，因为两个存储属性任何情况下都不会相互影响\n限制结构体属性的重叠访问对于保证内存安全不是必要的。保证内存安全是必要的，但因为访问独占权的要求比内存安全还要更严格——意味着即使有些代码违反了访问独占权的原则，也是内存安全的，所以如果编译器可以保证这种非专属的访问是安全的，那Swift就会允许这种行为的代码运行\n特别是当你遵循下面的原则时，他可以保证结构体属性的重叠访问是安全的\n你访问的是实例的存储属性，而不是计算属性或类的属性 结构体是本地变量的值，而非全局变量 结构体要么没有被闭包捕获，要么只被非逃逸闭包捕获了 如果编译器无法保证访问的安全性，他就不会允许那次访问\nhttps://swiftgg.gitbook.io/swift/swift-jiao-cheng/25_memory_safety\n苹果宣称Swift的特点是：快速、现代、安全、互动\n","date":"2021-05-06T00:00:00Z","permalink":"https://zjregee.github.io/p/memory-safety-in-swift/","title":"Memory safety in Swift"},{"content":"函数在Swift中是一等值，函数可以作为参数被传递到其他函数，也可以作为其他函数的返回值。\n函数式编程可以用规范的方式将函数作为参数装配为规模更大的程序。Objective-C通过引入block实现了对一等函数的支持：你可以将函数和闭包作为参数并轻松地使用内联的方式定义他们。然而，在Objective-C中使用它们并不像在Swift中一样方便，尽管两者在语意上完全相同。\n一个简单的案例 typealias Filter = CIImage -\u0026gt; CIImage // 一个模糊滤镜 func blur(radius: Double) -\u0026gt; Filter { return { image in // .... return outputImage } } // 一个覆盖颜色滤镜 func colorOverlay(color: NSColor) -\u0026gt; Filter { return { image in // .... return outputImage } } // 链式地将两个滤镜应用到载入的图像上 let blurRadius = 5.0 let overlayColor = NSColor.redColor().colorWithAlphaComponents(0.2) let blurredImage = blur(blurRadius)(image) let overlaidImage = colorOverlay(overlayColor)(blurredImage) //简单合为一体 let result = colorOverlay(overlayColor)(blur(blurRadius)(image)) 由于括号错综复杂，失去了可读性，我们可以自定义一个运算符来组合滤镜\nfunc composeFilters(filter1: Filter, _ filter2: Filter) -\u0026gt; Filter { return { image in filter2(filter1(image)) } } let myFilter1 = composeFilters(blur(blurRadius), colorOverlay(overlayColor)) let result1 = myFilter1(image) infix operator \u0026gt;\u0026gt;\u0026gt; { associativity left } func \u0026gt;\u0026gt;\u0026gt; (filter: Filter, filter2: Filter) -\u0026gt; Filter { return { image in filter2(filter1(image)) } } let myFilter2 = blur(blurRadius) \u0026gt;\u0026gt;\u0026gt; colorOverlay(overlayColor) let result2 = myFilter2(image) 柯里化 func add1(x: Int, _ y : Int) -\u0026gt; Int { return x + y } add1函数接受两个整形参数并返回它们的和。然而在Swift中，我们对该函数的定义还可以有另一个版本：\nfunc add2(x: Int) -\u0026gt; (Int -\u0026gt; Int) { return { y in return x + y } } 这里的add2函数接受第一个参数x之后，返回一个闭包，然后等待第二个参数y。这两个add函数的调用方法自然也是不同的：\nadd1(1, 2) add2(1)(2) 在Swift中，add2函数可以更简单的写为\nfunc add2(x: Int) -\u0026gt; Int -\u0026gt; Int { return { y in x + y } } 将一个接受多参数的函数变换为一系列只接受单个参数的函数，这个过程被称为柯里化 (Currying)\n如果我们有像add1一样未柯里化的函数，那么我们就必须用到它的全部两个参数来调用这个函数。然而，对于一个像add2一样被柯里化了的函数来说，我们有两个选择：可以使用一个或两个参数来调用。\n在之前的例子中，所有的函数全部已经被柯里化了——他们都接受一个附加的图像参数。按照柯里化的风格来定义滤镜，我们可以很容易地使用\u0026raquo;\u0026gt;运算符将他们进行组合。假如我们用这些函数未柯里化的版本来构建滤镜，虽然依然可以写出相同的滤镜，但由于这些滤镜接受的参数不同，定义一个统一的运算符会更加困难。\nMap和泛型 接受其他函数作为参数的函数有时被称为高阶函数。\n假如我们需要写一个函数，他接受一个给定的整形数组，通过计算得到并返回一个新数组，新数组各项为原数组中对应的整形数据加一。我们可以使用一个for循环简单的实现：\nfunc incrementArray(xs: [Int]) -\u0026gt; [Int] { var result: [Int] = [] for x in xs { result.append(x + 1) } return result } 但如果我们还需要一个函数，用于生成一个每项都为参数数组对应项两倍的新数组。这同样可以通过一个for循环来简单实现：\nfunc doubleArray1(xs: [Int]) -\u0026gt; [Int] { var result: [Int] = [] for x in xs { result.append(x * 2) } return result } 显然，这两个函数之间有大量重复代码，我们能不能将没有区别的地方抽象出来，并单独写一个体现这种模式并且更通用的函数呢？像这样的函数需要追加一个新参数来接受一个函数，这个参数能根据各个数组项计算得到新的整形数组：\nfunc computeIntArray(xs: [Int], transform: Int -\u0026gt; Int) -\u0026gt; [Int] { var result: [Int] = [] for x in xs { result.append(transform(x)) } return result } 现在我们想如何根据原数组得到一个新数组，可以向函数传递不同的参数。但是代码仍然不够灵活，假设我们想要得到一个布尔型的新数组，用于表示元数组中对应的数组是否为偶数，则我们可能又需要重新写一个函数。针对这个问题，我们可以使用泛型。\n无论是处理Bool还是Int的函数，唯一的区别在于类型签名 (type signature)。\nfunc map\u0026lt;Element, T\u0026gt;(xs: [Element], transform: Element -\u0026gt; T) -\u0026gt; [T] { var result: [T] = [] for x in xs { result.append(transform(x)) } return result } 对于任何一个Element的数组和transform: Element -\u0026gt; T 函数，他都会生成一个T的新数组。实际上，比起定义一个顶层map函数，按照Swift的惯例将map定义为Array的拓展会更合适\nextension Array { func map\u0026lt;Y\u0026gt;(transform: Element -\u0026gt; T) -\u0026gt; [T] { var result: [T] = [] for x in self { result.append(transform(x)) } return result } } 实际上像这样的map函数已经是Swift标准库的一部分了，它基于SequenceType协议被定义。在Swift标准库最初的版本中，顶层函数仍然是无处不在的，但伴随Swift2.0的诞生，这种模式被彻底的从标准库中移除了。随着协议拓展，当前第三方开发者不仅可以在Array这样的具体类型上进行定义，还可以在SequenceType一样的协议上来定义拓展。\nmap函数也并不是Swift标准数组库中唯一一个使用泛型的函数，在这里附上同样常用的filter和reduce的简单实现：\n// filter extension Array { func filter(includeElement: Elemnet -\u0026gt; Bool) -\u0026gt; [Element] { var result: [Element] = [] for x in self where includeElement(x) { result.append(x) } return result } } // reduce extension Array { func reduce\u0026lt;T\u0026gt;(initial: T, combine: (T, Element) -\u0026gt; T) -\u0026gt; T { var result = initial for x in self { result = combine(result, x) } return result } } // 用reduce重新定义map和filter extension Array { func mapUsingReduce\u0026lt;T\u0026gt;(transform: Element -\u0026gt; T) -\u0026gt; [T] { return reduce([]) { result, x in return result + [transform(x)] } } func filterUsingReduce(includeElement: Element -\u0026gt; Bool) -\u0026gt; [Element] { return reduce([]) { result, x in return includeElement(x) ? result + [x] : result } } } 我们能够使用reduce来表示所有这些函数，寿命了reduce能够通过通用的方法来体现一个相当常见的编程模式：遍历数组并计算结果。尽管通过reduce来定义一切是一个很有趣的练习，但是在实践中这往往不是一个好主意。原因在于，代码在运行期间可能大量复制生成的数组，反复分配内存、释放内存、以及复制大量内存中的内容，可能用一个可变结果数组定义map的效率会更高，这同样也取决于编译器的优化。\n利用泛型我们还可以定一个泛型函数，该函数能够讲仁义的接受两个元素的元组作为输入的函数进行柯里化处理，生成相应的柯里化版本：\nfunc curry\u0026lt;A, B, C\u0026gt;(f: (A, B) -\u0026gt; C) -\u0026gt; A -\u0026gt; B -\u0026gt; C { return { x in { y in f(x, y) } } } Something More 如果想写一个匿名函数的递归，比如实现一个阶乘，在Swift中你可能会这么写：\nlet f = { (n: Int) -\u0026gt; Int in n == 0 ? 1 : n * f(n - 1) } 但这样的写法是无法通过编译的。变量f的定义依赖于自身，无法初始化成功。对于这样的一个问题，解决的方法叫做Y combinator。\nlet F = { (g: Any) -\u0026gt; ((Int) -\u0026gt; Int) in { n in if n == 0 { return 1 } let h = g as! (Any) -\u0026gt; ((Int) -\u0026gt; Int) return n * h(g)(n - 1) } } let f = F(F) f(10) = 3628800 ({ (g: Any) -\u0026gt; ((Int) -\u0026gt; Int) in { n in if n == 0 { return 1 } let h = g as! (Any) -\u0026gt; ((Int) -\u0026gt; Int) return n * h(g)(n - 1) } })({ (g: Any) -\u0026gt; ((Int) -\u0026gt; Int) in { n in if n == 0 { return 1 } let h = g as! (Any) -\u0026gt; ((Int) -\u0026gt; Int) return n * h(g)(n - 1) } })(10) Swift中更优雅的实现lamda函数的递归，找到一个匿名的映射Y，将任何一个递归函数g的泛化，映射到g本身。而这个映射，就是所谓的Y combinator。\nfunc Y\u0026lt;T, R\u0026gt;(_ f: @escaping (@escaping (T) -\u0026gt; R) -\u0026gt; ((T) -\u0026gt; R)) -\u0026gt; ((T) -\u0026gt; R) { return { f(Y(f))($0) } } Y { f in { $0 == 0 ? 1 : $0 * f($0 - 1) } } (10) // 3628800 Y combinator是一个函数式编程中的问题，结论证明并没有那么直接易懂，其相关理论有兴趣的可以去自行了解。\n","date":"2021-05-02T00:00:00Z","permalink":"https://zjregee.github.io/p/%E5%87%BD%E6%95%B0%E5%BC%8Fswift%E5%88%9D%E6%AD%A5/","title":"函数式Swift初步"}]