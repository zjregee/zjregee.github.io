<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>分布式 on regee&#39;s Blog</title>
    <link>https://zjregee.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/</link>
    <description>Recent content in 分布式 on regee&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 02 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://zjregee.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Raft中的加速日志回溯</title>
      <link>https://zjregee.github.io/p/raft%E4%B8%AD%E7%9A%84%E5%8A%A0%E9%80%9F%E6%97%A5%E5%BF%97%E5%9B%9E%E6%BA%AF/</link>
      <pubDate>Sun, 02 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://zjregee.github.io/p/raft%E4%B8%AD%E7%9A%84%E5%8A%A0%E9%80%9F%E6%97%A5%E5%BF%97%E5%9B%9E%E6%BA%AF/</guid>
      <description>加速日志回溯是Raft论文实现中的一个可选功能。如果在完成6.824的过程中不实现的话，会在Lab2B、Lab2C的测试中出现问题。原因在于，当leader的appendEntries被拒时，论文默认的解决方案时反复减一回退重试，导致耗费很长时间才能找到同步位置，优化后可以一次性跳过更多的index，减少RPC往复。加速日志回溯的优化对于使陈旧的follower快速更新是有用的。
这一优化的实现方式并不是固定的，一个可能的原因在于作者认为在大多数部署中没有必要。在MIT的Student&amp;rsquo;s Guide to Raft中提出的实现方式如下：
如果follower的日志中没有prevLogIndex，他应该以conflictIndex = len(log)和conflictTerm = None返回。 如果follower的日志中有prevLogIndex，但是term不匹配，他应该返回conflictTerm = log[prevLogIndex].Term，然后conflictIndex的值等于在他的日志中第一个term等于conflictTerm的日志索引。 在收到有冲突的回复后，leader应该首先在其日志中搜索conflictTerm。如果他在他的日志中发现有该term的日志条目，就将nextIndex设置为其日志中这个term的最后一个日志条目索引之后的那一个位置。 如果他没有找到term等于conflictTerm的日志条目，就设置nextIndex = conflictIndex。 还有一个折半的解决方案是只使用conflictIndex，从而简化实现。但这样一来，leader有时会向follower发送更多的日志条目，而不是严格意义上世纪需要的，从而使他们达到最新状态。</description>
    </item>
    
    <item>
      <title>Simplified Data Processing on Large Clusters</title>
      <link>https://zjregee.github.io/p/simplified-data-processing-on-large-clusters/</link>
      <pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://zjregee.github.io/p/simplified-data-processing-on-large-clusters/</guid>
      <description>MapReduce: Simplified Data Processing on Large Clusters Abstract MapReduce是一个编程模型和一个相关的实现，用于处理和生成大型数据集。用户指定一个map函数来处理一个键/值对，生成一组中间键/值对，并指定一个reduce函数来合并与同一中间键相关的所有中间值。许多现实世界的任务都可以用这个模型来表达，以这种函数式编写的程序被自动并行化，并在一个大型的组合机集群上执行。运行时系统负责分割输入数据的细节，在一组机器上调度程序的执行，处理机器故障，以及管理所需的机器间通信。这使得没有任何并行和分布式系统经验的程序员可以轻松地利用大型分布式系统的资源。
Introduction Google中的许多人使用MapReduce实现了数百种特殊用途的计算，这些计算处理了大量的原始数据，如抓取的文件、网络请求日志等，以计算各种衍生数据。大多数这样的计算在概念上是直接了当的。然而，输入的数据通常很大，计算必须分布在数百或数千台机器上，以便在合理的时间内完成。如何对计算进行分工，分配数据，以及处理故障等这些问题，会用大量复杂的代码掩盖最初的简单计算。
为了处理这种复杂性，设计了一个新的抽象，它允许我们表达我们试图执行的简单计算，但将并行化、容错、数据分配和负载平衡等混乱的东西隐藏在一个库中。所以，MapReduce的主要贡献是一个简单而强大的接口，能够实现大规模计算的自动并行化和分布以及在大型商用PC集群上的高性能。
Progrmaming Model 该计算接受一组输入键/值对，并产生一组输出键/值对。MapReduce库的用户将计算表达为两个函数，map和reduce。
由用户编写的map函数需要一个输入对，并产生一组中间键/值对。MapReduce库将所有与同一中间键I相关的中间值分组，并将它们传递给reduce函数。reduce函数同样是由用户编写的，它接受一个中间值I和该键的一组值。它将这些值合并起来，形成一个可能更小的值集。一般来说，每次reduce调用只产生0或1个输出值。中间值通过一个迭代器提供给用户的reduce函数。这使得我们能够处理那些大到无法在内存中容纳的数值列表。
举个🌰 考虑这样一个问题：在一大批文件中计算每个词的出现次数的问题。
用户可以编写这样的map、reduce函数伪代码：
map(String key, String value): // key: document name // value: document contents for each word w in value: EmitIntermediate(w, &amp;#34;1&amp;#34;); reduce(String key, Iterator values): // key: a word // values: a list of coutns int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); map函数给出每个单词和相关的出现次数（在这个简单的例子中只有“1”）。reduce函数将map为某一特定单词给出的所有计数相加。
用户在使用MapReduce库时可以编写代码来填写mapreduce中规范的对象（包括输入和输出文件的名称，以及可选的调整参数），然后调用相应函数把规范对象传递给它。
Types 理论上，用户提供的map和reduce函数应该具有如下相关联的类型：</description>
    </item>
    
  </channel>
</rss>
